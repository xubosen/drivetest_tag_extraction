{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0af83a-da80-46b9-a0a8-4e70a3399c00",
   "metadata": {},
   "source": [
    "# Drive Test Tag Generation With BERTopic\n",
    "Generate tags for the written portion of the chinese driving exam using BERTopic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf9df9-a4e7-4134-9652-6a522acf2189",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "Loading data fom local database into a pandas dataframe"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### a) Load data into question bank class",
   "id": "921e1d009ed0cc7b"
  },
  {
   "cell_type": "code",
   "id": "76b55877-b5f6-4901-841d-4187a9511e0d",
   "metadata": {},
   "source": [
    "from qb.question import Question\n",
    "from qb.question_bank import QuestionBank\n",
    "from data_storage.database.json_database import LocalJsonDB\n",
    "\n",
    "db = LocalJsonDB(\"data_storage/database/json_db/data.json\",\n",
    "                 \"data_storage/database/json_db/images\")\n",
    "qb : QuestionBank = db.load()\n",
    "print(qb.question_count())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### b) Fill in questions without images with a blank image",
   "id": "bcdffb88d8475934"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "def make_blank_img(path: str) -> None:\n",
    "    \"\"\" Create a blank image and save it to the specified path. \"\"\"\n",
    "    img = Image.new('RGB', (10, 10), color='white')\n",
    "    img.save(path)"
   ],
   "id": "ef17d7860f546d18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_blank_img_path() -> str:\n",
    "    \"\"\" Create a path for the blank image. \"\"\"\n",
    "    return f\"data_storage/database/json_db/images/00blank.webp\"\n",
    "make_blank_img(get_blank_img_path())"
   ],
   "id": "4451d62d3a9f1c24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### c) Convert question bank to pandas dataframe",
   "id": "66844d224eb7c8d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "def qb_to_df(qb: QuestionBank) -> DataFrame:\n",
    "    data = {\n",
    "        \"ID\": [],\n",
    "        \"Question\": [],\n",
    "        \"Answer Choices\": [],\n",
    "        \"Answer\": [],\n",
    "        \"Chapter\": [],\n",
    "        \"Image Path\": []\n",
    "    }\n",
    "    for chapter_id in qb.get_all_chapter_num():\n",
    "        chapter_description = qb.describe_chapter(chapter_id)\n",
    "        qid_lst = qb.get_qids_by_chapter(chapter_id)\n",
    "        for qid in qid_lst:\n",
    "            question: Question = qb.get_question(qid)\n",
    "            data[\"ID\"].append(qid)\n",
    "            data[\"Question\"].append(question.get_question())\n",
    "            data[\"Answer Choices\"].append(\", \".join(question.get_answers()))\n",
    "            data[\"Answer\"].append(question.get_correct_answer())\n",
    "            data[\"Chapter\"].append(chapter_description)\n",
    "            data[\"Image Path\"].append(question.get_img_path() if question.get_img_path() else get_blank_img_path())\n",
    "    return pd.DataFrame(data)\n",
    "question_bank = qb_to_df(qb)"
   ],
   "id": "6c8223a4b098fe44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(question_bank.shape)\n",
    "question_bank.head()"
   ],
   "id": "6f47101cc999dd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c367c9da-7000-440e-afed-82729b20536c",
   "metadata": {},
   "source": [
    "## 2. Format Data\n",
    "Convert Question Bank to a form suitable for BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b1553f5-1bc5-4c33-98ef-296f43474ca1",
   "metadata": {},
   "source": [
    "from typing import List\n",
    "def make_docs_images(question_bank: DataFrame) -> (List[str], List[str]):\n",
    "    docs = []\n",
    "    images = []\n",
    "    for key in question_bank.index:\n",
    "        question = question_bank.loc[key, \"Question\"]\n",
    "        answer_choices = question_bank.loc[key, \"Answer Choices\"]\n",
    "        answer = question_bank.loc[key, \"Answer\"]\n",
    "        chapter = question_bank.loc[key, \"Chapter\"]\n",
    "        # Combine all parts into a single document\n",
    "        doc = f\"章节: {chapter}\\n 题目: {question}\\n 选项: {answer_choices}\\n 答案: {answer}\"\n",
    "        img_path = question_bank.loc[key, \"Image Path\"]\n",
    "\n",
    "        docs.append(doc)\n",
    "        images.append(img_path if img_path else None)\n",
    "    return docs, images\n",
    "docs, images = make_docs_images(question_bank)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc221026-6187-4e5e-97f8-6a11a6dd170e",
   "metadata": {},
   "source": [
    "# Display the first 5 documents and images\n",
    "for i in range(5):\n",
    "    print(docs[i], \"\\n\")\n",
    "    print(images[i], \"\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Naive Processing",
   "id": "6f47c8d2ece88148"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### a) Set up model\n",
    "#### Set up the visual component"
   ],
   "id": "c19d1e25973e5ffe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import VisualRepresentation"
   ],
   "id": "1c669dd17986f81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up the visual component\n",
    "visual_model = VisualRepresentation()"
   ],
   "id": "13427c194e3f7f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "representation_model = {\n",
    "    \"Visual_Aspect\": visual_model,\n",
    "}"
   ],
   "id": "ba58151faf6cb9ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Set up the embedding model",
   "id": "68896e25289917c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "embedding_model = \"distiluse-base-multilingual-cased-v1\"",
   "id": "81b36e77a14d985c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Put the model together\n",
    "topic_model = BERTopic(embedding_model=embedding_model,\n",
    "                       representation_model=representation_model,\n",
    "                       verbose=True)"
   ],
   "id": "18704befda6d24e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### b) Fit the model",
   "id": "af67f137d1897f7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topic_model.fit(docs, images=images)",
   "id": "44337bb636bdd80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### c) Save the model",
   "id": "f2f5749b9644edb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "time = str(datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "model_save_path = f\"data_storage/model_dir/{time}\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "print(model_save_path)"
   ],
   "id": "54398d1f89ad0cd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topic_model.save(model_save_path, serialization=\"pytorch\", save_ctfidf=True, save_embedding_model=embedding_model)",
   "id": "e293393c918236cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### d) Inspect the model",
   "id": "a04f0c92ef10d97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topic_model.visualize_topics()",
   "id": "a3d0a7bb02e56009",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# View a sample of the topics and their representative documents\n",
    "def view_topic_samples(topic_model, n_topics=5, n_docs_per_topic=5):\n",
    "    \"\"\"\n",
    "    Display a sample of topics and their representative documents.\n",
    "    \"\"\"\n",
    "    for topic_id in range(n_topics):\n",
    "        print(f\"Topic {topic_id}:\")\n",
    "        print(f\"Topics: {topic_model.get_topic(topic_id)}\")\n",
    "        # Get the representative documents for the topic\n",
    "        representative_docs = topic_model.get_representative_docs(topic_id)\n",
    "        # Print a sample of the documents\n",
    "        for doc in representative_docs[:min(len(representative_docs), n_docs_per_topic)]:\n",
    "            print(f\"- {doc}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Call the function with the trained model and documents\n",
    "view_topic_samples(topic_model, n_topics=5, n_docs_per_topic=5)"
   ],
   "id": "bb04f794283d2e1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topic_model.get_topic(36)",
   "id": "89566d309d4ee7d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topic_model.get_representative_docs(36)",
   "id": "564b3d628e1d99b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e3820c25a305839"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Multimodal Topic Modeling Through Multimodal Embeddings",
   "id": "c42a41acaa991f7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### a) Create custom embeddings",
   "id": "8653b5b0f0f867fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To improve upon the quality of the tags, we need to first make sure we are taking both the image and the text into account when generating the embeddings. This can be done by using a model that embeds images and text into the same space. For questions that have images, we will embed both the text and the image and take the average.",
   "id": "d19b5524507b409c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T21:06:16.185431Z",
     "start_time": "2025-06-24T21:06:06.081151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotImageClassification\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"google/siglip-base-patch16-256-multilingual\")\n",
    "model = AutoModelForZeroShotImageClassification.from_pretrained(\"google/siglip-base-patch16-256-multilingual\")"
   ],
   "id": "d3bf6a9a109ca9f7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T21:10:45.020877Z",
     "start_time": "2025-06-24T21:10:45.016026Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b0a72f0107b09d49",
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after class definition on line 3 (3875396116.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mdef encode(docs: List[str], images: List[str], model: AutoModelForZeroShotImageClassification) -> np.ndarray:\u001B[39m\n    ^\n\u001B[31mIndentationError\u001B[39m\u001B[31m:\u001B[39m expected an indented block after class definition on line 3\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T21:10:45.429117Z",
     "start_time": "2025-06-24T21:10:45.427203Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4078604f7870f9ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T21:10:45.800791Z",
     "start_time": "2025-06-24T21:10:45.798402Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6ac1f7f1d75b8b8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5d1b4ef6948dbabb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drivetest_tag_gen",
   "language": "python",
   "name": "drivetest_tag_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
